{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBQnjUbWsEW-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import skimage.measure\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from model_definition import unet\n",
    "\n",
    "from prediction import predict_image\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input image for prediction\n",
    "\n",
    "* This assumes that an image is taken once a day \n",
    "* It is saved in a new folder titled DD-MM-YY\n",
    "* The image is called 'image.jpg'\n",
    "\n",
    "The image is read, resized, and formatted as required by the model\n",
    "\n",
    "We then show the input image, the non-thresholded image, and the thresholded image\n",
    "\n",
    "And finally make a prediction of cell count based on the thresholded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "input_path = 'images/'\n",
    "\n",
    "# load all folder in the image folder\n",
    "# the folders are named by date dd-mm-yy\n",
    "# if the folder name is not equal to todays ate, remove from list\n",
    "input_ids = next (os.walk(input_path))[1]\n",
    "for l in input_ids:\n",
    "    if l != datetime.today().strftime('%Y-%m-%d'):\n",
    "        input_ids.remove(l)\n",
    "\n",
    "# format model input based on folder list - should only be 1\n",
    "X_input = np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "sizes_test = []\n",
    "\n",
    "# resize input image, assuming image is called 'image.jpg'\n",
    "for n, id_ in tqdm(enumerate(input_ids), total=len(input_ids)): \n",
    "    path = input_path + id_\n",
    "    print(path)\n",
    "    img = imread(path + '/image.jpg')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_input[n] = img\n",
    "\n",
    "end = timer()\n",
    "\n",
    "# define model parameters\n",
    "kernel_size = 8\n",
    "\n",
    "model = unet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, kernel_size)\n",
    "\n",
    "#Load saved UNET model\n",
    "unet_model_name = 'checkpoint_unet.h5'\n",
    "checkpoint_filepath = unet_model_name\n",
    "model.load_weights(checkpoint_filepath);\n",
    "\n",
    "# prediction \n",
    "preds_input = model.predict(X_input, verbose=1)\n",
    "preds_input_t = (preds_input > 0.5).astype(np.uint8)\n",
    "\n",
    "ix = 0\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10,10))\n",
    "\n",
    "# show input image\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[0].imshow(X_input[0])\n",
    "\n",
    "# show non-thresholded image\n",
    "ax[1].set_title(\"Predicted without Threshold\")\n",
    "ax[1].imshow(np.squeeze(preds_input[0]), cmap='gray')\n",
    "\n",
    "# show thresholded image\n",
    "ax[2].set_title(\"Predicted with Threshold\")\n",
    "ax[2].imshow(np.squeeze(preds_input_t[0]), cmap='gray')\n",
    "\n",
    "for a in ax:\n",
    "  a.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# predict cell count and display\n",
    "limg = skimage.measure.label(preds_input_t[ix], connectivity=2, return_num=True)\n",
    "print(\"Cell count: \", np.max(limg[0]))\n",
    "\n",
    "#TODO\n",
    "# generate report of prediction data and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR8Cx4ithco2"
   },
   "outputs": [],
   "source": [
    "# Define common variables:\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "TRAIN_PATH = 'train/'\n",
    "TEST_PATH = 'test/'\n",
    "\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoawWq7_sOXx"
   },
   "outputs": [],
   "source": [
    "# Define X train and Y train tensors:\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FiHlA9mH6f9",
    "outputId": "3c6b6fb7-89a8-4044-a70f-a0247c7b81dd"
   },
   "outputs": [],
   "source": [
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4cOomEiIpy4",
    "outputId": "52214bb9-7e9f-41f3-e3c8-edfa1ee62250"
   },
   "outputs": [],
   "source": [
    "# Data Cleaning:\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img  # Fill empty X_train with values from img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  \n",
    "            \n",
    "    Y_train[n] = mask   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qMg813AsYN-"
   },
   "outputs": [],
   "source": [
    "# Test images:\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2ktvRRGIxVq",
    "outputId": "45b9e8f4-9ecf-4737-90f8-e5805dffa712"
   },
   "outputs": [],
   "source": [
    "# Data Cleaning:\n",
    "\n",
    "sizes_test = []\n",
    "\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1vAxHeTTCjF",
    "outputId": "a89a4c55-0b71-4f3c-afd3-b1f6dd1b930a"
   },
   "outputs": [],
   "source": [
    "# Check tensor shapes:\n",
    "X_train = tf.random.shuffle(X_train, seed=101).numpy()\n",
    "Y_train = tf.random.shuffle(Y_train, seed=101).numpy()\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "biitBgnjshwO",
    "outputId": "f98cd2f4-a404-422f-e02b-000ed8b3fb57"
   },
   "outputs": [],
   "source": [
    "# Display random x_train and y_train image:\n",
    "\n",
    "l=1\n",
    "while l <= 5:\n",
    "    ix = random.randint(0, len(train_ids))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,8))\n",
    "\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[0].imshow(X_train[ix])\n",
    "\n",
    "    ax[1].set_title(\"Ground Truth\")\n",
    "    ax[1].imshow(np.squeeze(Y_train[ix]))\n",
    "\n",
    "    for a in ax:\n",
    "      a.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    l+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foyhKBs2_zex",
    "outputId": "d36a1673-824a-426e-d4a0-7f893e548583"
   },
   "outputs": [],
   "source": [
    "kernel_size = 8\n",
    "\n",
    "model = unet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2c6g19jtPrP",
    "outputId": "c329b1b9-75e9-4c5a-e17d-05499193c586"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    #tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, monitor='accuracy'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=32, epochs=200, callbacks=[callbacks,mcp_save,reduce_lr_loss])\n",
    "# results = model.fit(X_train[:100], Y_train[:100], epochs=250, callbacks=callbacks)\n",
    "\n",
    "end = timer()\n",
    "print(\"\\nTime taken for Model to Run: \", end - start, \"seconds\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Hhrz1VjdRdx_",
    "outputId": "753b50f7-e6fe-4b29-dc71-2cfb43186455"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss at each epoch\n",
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = results.history['accuracy']\n",
    "val_acc = results.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yP45r07KtUy9",
    "outputId": "8f04dde3-fc8b-4e73-fd9b-d6471e67dc83"
   },
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    " \n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRO78dyjRr9F"
   },
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "fcn8_model_name = 'checkpoint_fcn8.h5'\n",
    "unet_model_name = 'checkpoint_unet.h5'\n",
    "model.save(unet_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "checkpoint_filepath = 'unet_model_name'\n",
    "%model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24WCQV32MbTh"
   },
   "outputs": [],
   "source": [
    "# Plot model\n",
    "tf.keras.utils.plot_model(\n",
    "     model, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "     rankdir='TB', expand_nested=False, dpi=96\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "blob_segmentation_from_yt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
